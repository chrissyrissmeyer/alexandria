#!/usr/bin/env ruby

puts 'Loading environment...'
require File.expand_path('../../config/environment', __FILE__)
puts "Running in #{Rails.env} mode..."

require 'trollop'

options = Trollop.options do
  opt :data, 'Data file(s)/directory', type: :strings
  opt :format, 'Metadata format (csv, mods, etd, cyl)', type: :string
  opt :metadata, 'Metadata file(s)/directory', type: :strings
  opt :number, 'Only ingest N records', type: :integer
  opt :skip, 'Skip the first N records', default: 0
  opt :verbose, 'Provide additional output', default: false
end

require File.expand_path('../../lib/importer', __FILE__)
AdminPolicy.ensure_admin_policy_exists

# lib/exceptions.rb
require 'exceptions'

require 'fileutils'
require 'find'
require 'json'
require 'traject'

metadata_ext = case options[:format]
               when 'csv'
                 '.csv'
               else
                 '.xml'
               end

# For each argument passed to --metadata, if it's a file, add it
# to the array, otherwise drill down and add each file within to
# the array
meta = if options[:metadata]
         options[:metadata].map do |arg|
           if File.file?(arg)
             arg
           else
             next unless Dir.exist?(arg)
             files = []
             Find.find(arg) do |path|
               next unless File.extname(path) == metadata_ext
               files << path
             end
             files
           end
         end.flatten
       else
         []
       end

# For each argument passed to --data, if it's a file, add it to
# the array, otherwise drill down and add each file within to the
# array
data = if options[:data]
         if options[:format] == 'cyl'
           []  # No need to expand files for cylinder import
         else
           options[:data].map do |arg|
             if File.file?(arg)
               arg
             else
               next unless Dir.exist?(arg)
               datas = []
               Find.find(arg) do |path|
                 next if File.directory?(path)
                 datas << path
               end
               datas
             end
           end.flatten
         end
       end
data ||= []

if options[:verbose]
  puts
  puts 'Metadata inputs:'
  meta.each { |m| puts m }
  puts
  puts 'Data inputs:'
  data.each { |d| puts d }
end

######################
# Begin ingest process
######################
start_overall = Time.now
ingests = 0

puts "Import start time: #{start_overall.strftime("%Y-%m-%d %H:%M:%S")}"

begin
  case options[:format]
  when 'csv'
    meta.each do |m|
      head, tail = Importer::CSV.split(m)

      if options[:skip] >= tail.length
        raise ArgumentError, "Number of records skipped (#{options[:skip]}) greater than total records to ingest"
      end

      tail.each_with_index do |row, count|
        next if options[:skip] > count
        next if options[:number] && options[:number] <= ingests

        start_record = Time.now

        attrs = Importer::CSV.csv_attributes(head, row)
        files = if attrs[:files].nil?
                  []
                else
                  data.select { |d| attrs[:files].include? File.basename(d) }
                end

        if options[:verbose]
          puts
          puts "Object attributes for item #{count + 1}:"
          puts attrs.each { |k, v| puts "#{k}: #{v}" }
          puts
          puts "Associated files for item #{count + 1}:"
          puts files.each { |f| puts f }
        end

        begin
          Importer::CSV.import(
            attributes: attrs,
            files: files
          )
          end_record = Time.now
          puts "Ingested record #{count + 1} of #{tail.length} "\
                "in #{end_record - start_record} seconds (#{end_record - start_overall} seconds elapsed)"
          ingests += 1
        # Other exceptions are already handled in CSV.import
        rescue => e
          puts e
          puts e.backtrace
          raise IngestError.new(reached: count)
        rescue Interrupt
          puts "\nIngest stopped, cleaning up..."
          raise IngestError.new(reached: count)
        end
      end
    end
  when 'mods'
    if options[:skip] >= meta.length
      raise ArgumentError, "Number of records skipped (#{options[:skip]}) greater than total records to ingest"
    end

    # TODO: this currently assumes one record per metadata file
    meta.each_with_index do |m, count|
      next if options[:skip] > count
      next if options[:number] && options[:number] <= ingests

      start_record = Time.now

      d = data.select do |f|
        # FIXME: find a more reliable test
        meta_base = File.basename(m, '.xml')
        data_base = File.basename(f, File.extname(f))
        data_base.include?(meta_base) || meta_base.include?(data_base)
      end

      if options[:verbose]
        puts
        puts "Object metadata for item #{count + 1}:"
        puts m
        puts
        puts "Associated files for item #{count + 1}:"
        puts d.each { |f| puts f }
      end

      begin
        Importer::Mods.import(m, d)
        end_record = Time.now
        puts "Ingested record #{count + 1} of #{meta.length} "\
             "in #{end_record - start_record} seconds (#{end_record - start_overall} seconds elapsed)"
        ingests += 1
      rescue => e
        puts e
        puts e.backtrace
        raise IngestError.new(reached: count)
      rescue Interrupt
        puts "\nIngest stopped, cleaning up..."
        raise IngestError.new(reached: count)
      end
    end
  when 'etd'
    # lib/proquest
    require 'proquest'

    [Settings.download_root,
     Settings.marc_directory,
     Settings.proquest_directory].each do |dir|
      FileUtils.mkdir_p dir unless Pathname.new(dir).exist?
    end

    if data.empty?
      $stderr.puts 'Nothing found in the data path you specified.'
      exit 1
    end

    Dir.mktmpdir do |temp|
      # Don't unzip ETDs we won't use
      etds = data.drop(options[:skip]).map.with_index do |zip, i|
        # i starts at zero, so use greater-than instead of >=
        if !options[:number] || options[:number] > i
          Proquest.extract(zip, "#{temp}/#{File.basename(zip)}")
        end
      end.compact

      if etds.empty?
        raise ArgumentError, "Number of records skipped (#{options[:skip]}) greater than total records to ingest"
      end

      xml = etds.map { |e| e[:xml] }
      marc = MARC::XMLReader.new(
        StringIO.new(Importer::ETD.fetch_marc(xml))
      )

      marc.each_with_index do |record, count|
        next if options[:number] && options[:number] <= ingests

        start_record = Time.now

        # https://github.com/traject/traject/blob/master/lib/traject/indexer.rb#L101
        indexer = Traject::Indexer.new
        indexer.load_config_file('lib/traject/etd_config.rb')
        indexer.settings(etd: etds[count])

        if options[:verbose]
          puts
          puts "Object attributes for item #{count + 1}:"
          puts record
          puts
          puts "Associated data for item #{count + 1}:"
          puts etds.each { |f| puts f }
        end

        begin
          indexer.writer.put indexer.map_record(record)
          indexer.writer.close
          # Since earlier we skipped the unzip operations we don't
          # need, the array of records to iterate over is smaller, so
          # we modify the numbers here so that we still get the
          # correct "Ingested X of out Y records" readout.
          end_record = Time.now
          puts "Ingested record #{count + 1 + options[:skip]} of #{etds.length + options[:skip]} "\
               "in #{end_record - start_record} seconds (#{end_record - start_overall} seconds elapsed)"
          ingests += 1
        rescue => e
          puts e
          puts e.backtrace
          raise IngestError.new(reached: count)
        rescue Interrupt
          puts "\nIngest stopped, cleaning up..."
          raise IngestError.new(reached: count)
        end
      end
    end
  when 'cyl'
    files_dir = Array(options[:data]).first
    puts "Audio files directory: #{files_dir}" if options[:verbose]

    begin
      importer = Importer::Cylinder.new(meta, files_dir, options)
      importer.run
    rescue => e
      puts e
      puts e.backtrace
      raise IngestError.new(reached: options[:skip] + importer.imported_records_count)
    ensure
      ingests = importer.imported_records_count
    end
  end  # case/when

  end_overall = Time.now
  puts "Ingested #{ingests} records in #{(end_overall - start_overall) / 60} minutes"
rescue IngestError => e
  puts
  end_overall = Time.now
  puts "Ingested #{ingests} records in #{(end_overall - start_overall) / 60} minutes"
  puts
  puts "To continue this ingest, re-run the command with `--skip #{e.reached}`"
  exit 1
end
